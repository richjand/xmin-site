<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Measuring Changes in Ability with State Space Models | Richard&#39;s Page</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    
  </head>

  <body>
    <nav>
    <ul class="menu">
      
      <li><a href="/">Home</a></li>
      
      <li><a href="/post/">Posts</a></li>
      
    </ul>
    <hr/>
    </nav>

<div class="article-meta">
<h1><span class="title">Measuring Changes in Ability with State Space Models</span></h1>
<h2 class="author">Richard Anderson</h2>
<h2 class="date">2021/08/23</h2>
</div>

<main>

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<p>A fairly common situation in my line of work is that you are attempting to understand the value of some latent variable from various sources of data collected at irregular intervals (think measuring power from home runs, exit velo, etc…). One wrinkle is that the latent variable is changing over time and we want to understand how much the data we observed should affect our beliefs about the latent variable. One can approach this using a state space model where we observe values <span class="math inline">\(y\)</span> at time <span class="math inline">\(t\)</span> that are generated according to some latent variable <span class="math inline">\(\mu_{t}\)</span>.</p>
<p>Formally, our data generating process is:</p>
<p><span class="math inline">\(y_{t} \sim N(\mu_{t}, \sigma)\)</span></p>
<p><span class="math inline">\(\mu_{t} \sim N(\mu_{t-1}, \sigma_{state})\)</span></p>
<p>This just says that <span class="math inline">\(y\)</span> is a noisy measure of ability, <span class="math inline">\(\mu\)</span>, and that the expectation of <span class="math inline">\(\mu\)</span> in any given period is just <span class="math inline">\(\mu\)</span> from the previous period with some random noise <span class="math inline">\(\sigma_{state}\)</span>. This model will learn the amount of period-to-period noise as well as the amount of noise in the mapping between <span class="math inline">\(\mu\)</span> and <span class="math inline">\(y\)</span> which will give us an estimate of how much we should update our beliefs about <span class="math inline">\(\mu\)</span> given what we observe in each period.</p>
<p>We can extend this to multiple individuals by adding a prior for each individual’s <span class="math inline">\(\mu\)</span>.</p>
<p><span class="math inline">\(y_{i,t} \sim N(\mu_{i,t}, \sigma)\)</span></p>
<p><span class="math inline">\(\mu_{i,t} \sim N(\mu_{i,t-1}, \sigma_{state})\)</span></p>
<p><span class="math inline">\(\mu_{i} \sim N(\mu_{ability}, \sigma_{mu})\)</span></p>
<div id="simulating-an-nfl-season" class="section level2">
<h2>Simulating an NFL Season</h2>
<p>The basics of the simulation are that each team has an initial ability <span class="math inline">\(\mu_{i, 1}\)</span> and that ability is changing over time. We see each team play another team 16 times and we are trying to infer the ability of the two teams involved in the game from the score of the game.</p>
<p>We’ll set our number of teams to be 32 and the number of games to be 16. <span class="math inline">\(\alpha\)</span> is set to three and can be thought of as the built-in advantage for team 1 which in a real application would be something like a home field advantage, assuming that team 1 is the home team. <span class="math inline">\(\sigma\)</span> is the amount of variance in the score difference given the ability of the two teams, <span class="math inline">\(\sigma_{start}\)</span> is the amount of variance in team ability in week 1, and <span class="math inline">\(\sigma_{state}\)</span> is the week to week variance in team ability.</p>
<p>In this example we have some kind of indicator about a team’s ability going into week 1 that we’ll call x_prior. This could be something like pre-season power rankings, performance in the previous season, or any number of other pieces of information that could give us a clue to how good a team is before we’ve watched them play.</p>
<pre class="r"><code>library(dplyr)
library(rstan)
library(purrr)
library(ggplot2)
library(bayesplot)

set.seed(1234)

theme_set(theme_bw())

n_teams &lt;- 32
n_weeks &lt;- 16
alpha &lt;- 3
sigma &lt;- 7
sigma_start = 3
sigma_state = 1
x_prior &lt;- rnorm(n_teams, 0, 1)
x_beta &lt;- .5
mu_start &lt;- rnorm(n_teams, x_prior * x_beta, sigma_start)</code></pre>
<p>We can define a function gen_mu_ts that will take a team’s starting ability, draw random shocks for each week, and return the team’s ability for each of the 16 weeks.</p>
<pre class="r"><code>gen_mu_ts &lt;- function(mu_start, n_weeks, sigma_state) {
  changes &lt;- rnorm(n_weeks-1, 0, sigma_state)
  mu_team &lt;- cumsum(c(mu_start, changes))
  return(mu_team)
}

print(gen_mu_ts( mu_start[1],n_weeks, sigma_state))</code></pre>
<pre><code>##  [1] -2.7318530 -2.7394577 -0.9623733 -2.1009810 -0.7331539  0.5964109
##  [7]  0.9328837  0.9397766  0.4843078  0.1177839  0.7660705  2.8363413
## [13]  2.6829429  1.2922420  0.5686602  0.8269220</code></pre>
<p>Next, we’ll create a function that sets matchups for each week.</p>
<pre class="r"><code>create_matchups &lt;- function(n_teams, n_weeks){
  weeklist &lt;- list()
  for (i in 1:n_weeks){
    teams &lt;- 1:n_teams
    matchlist &lt;- list()
    for (k in 1:(n_teams/2)){
      match &lt;- sample(teams, 2)
      teams &lt;- teams[!teams %in% match]
      matchlist[[k]] &lt;- match
    }
    df &lt;- data.frame(team_1 = sapply(matchlist, &#39;[&#39;, 1),
                     team_2 = sapply(matchlist, &#39;[&#39;, 2),
                     week = i
    )
    weeklist[[i]] &lt;- df 
  }
  return_df &lt;- dplyr::bind_rows(weeklist)
  return(return_df)
}

games &lt;- create_matchups(n_teams, n_weeks)
head(games)</code></pre>
<pre><code>##   team_1 team_2 week
## 1      8     29    1
## 2     18     14    1
## 3     28     19    1
## 4      2      6    1
## 5     32     15    1
## 6      9     26    1</code></pre>
<p>We’ll use our <code>get_mu_ts()</code> function to generate team abilities over time and put all of those abilities into a data frame with the matchups generated above.</p>
<pre class="r"><code>team_abilities &lt;- unlist(map(.x = mu_start, .f = gen_mu_ts, n_weeks = n_weeks, sigma_state = sigma_state))
team_id &lt;- unlist(lapply(1:n_teams, rep, n_weeks))
week &lt;- rep(1:n_weeks, n_teams)
abilities &lt;- data.frame(ability = team_abilities,
                        team_id = team_id,
                        week = week)

games &lt;- games %&gt;%
  left_join(abilities, by = c(&#39;team_1&#39; = &#39;team_id&#39;,
                              &#39;week&#39; = &#39;week&#39;)) %&gt;%
  rename(team_1_mu = ability) %&gt;%
  left_join(abilities, by = c(&#39;team_2&#39; = &#39;team_id&#39;,
                              &#39;week&#39; = &#39;week&#39;)) %&gt;%
  rename(team_2_mu = ability)

head(games)</code></pre>
<pre><code>##   team_1 team_2 week team_1_mu team_2_mu
## 1      8     29    1 -1.671009  1.962196
## 2     18     14    1 -1.946148 -2.873314
## 3     28     19    1 -3.985254 -5.836680
## 4      2      6    1 -1.365060 -3.769952
## 5     32     15    1 -2.246697 -2.842208
## 6      9     26    1  4.066263 -3.044163</code></pre>
<p>The last thing to do before fitting the model is to generate our dependent variable, the difference in score between team 1 and team 2.</p>
<pre class="r"><code>games$score_diff &lt;- rnorm(nrow(games), alpha + games$team_1_mu - games$team_2_mu, sigma)</code></pre>
</div>
<div id="the-model" class="section level2">
<h2>The Model</h2>
<p>We’ll fit our model in stan.</p>
<pre class="r"><code>stan_mod &lt;- stan_model(model_code = &quot;
data {
  int&lt;lower = 1&gt; T;       // Number of time periods
  int&lt;lower=0&gt; N;         // number of observations
  int&lt;lower=1&gt; K;         //number of teams
  int&lt;lower=1&gt; week[N];
  int&lt;lower=1&gt; team_1[N];
  int&lt;lower=1&gt; team_2[N];
  row_vector[K] x;              // Independent variable for prior
  real y[N];              // final score difference
}
parameters {
  real alpha;                    // standard home field advantage
  real beta_x;                   // coefficient on prior
  real&lt;lower = 0&gt; sigma_state;   // week to week variation
  real&lt;lower = 0&gt; sigma_ability; // team ability variation
  real&lt;lower = 0&gt; sigma;         // residual standard error
  matrix[T,K] eta_mu; //Matrix of team abilities
}
transformed parameters {
  matrix[T,K] mu; // Team abilities
  mu[1] = x * beta_x + sigma_ability * eta_mu[1];
  for (t in 2:T){
    mu[t] = mu[t-1] + sigma_state * eta_mu[t];
  }
}

model {
  vector[N] mu_diff;

  alpha ~ normal(3,1);
  sigma_state ~ normal(1,1);
  sigma_ability ~ normal(3,1);
  sigma ~ normal(7,3);
  beta_x ~ normal(0,1);
  to_vector(eta_mu) ~ normal(0,1);
  for (n in 1:N){
    mu_diff[n] = mu[week[n],team_1[n]] - mu[week[n], team_2[n]];
  }  
  
  //likelihood  
  y ~ normal(alpha + mu_diff, sigma);
}
generated quantities{
  vector[N] yrep;
  for (n in 1:N){
    yrep[n] = normal_rng(alpha + mu[week[n],team_1[n]] - mu[week[n], team_2[n]], sigma);
  }
}
                     &quot;)

standat &lt;- list(T = n_weeks,
                N = nrow(games),
                K = n_teams,
                week = games$week,
                team_1 = games$team_1,
                team_2 = games$team_2,
                x = x_prior,
                y = games$score_diff
                )

fit &lt;- sampling(stan_mod, data = standat, chains = 4, iter = 4000, cores = 2)</code></pre>
</div>
<div id="results" class="section level2">
<h2>Results</h2>
<p>So how did the model do? We’re looking here to see if the stan model returned the parameters we set in the simulation. If the model is able to do that we should be in good shape to take it to real data!</p>
<p>Each of the variables we set in the simulation are between the 2.5th and 97.5th percentiles so I’d say this model does pretty well returning our known unknowns!</p>
<pre class="r"><code>print(fit, pars = c(&#39;alpha&#39;,&#39;beta_x&#39;,&#39;sigma_state&#39;,&#39;sigma_ability&#39;,&#39;sigma&#39;))</code></pre>
<pre><code>## Inference for Stan model: 8a17d294cb854e7c48f4f764537cbfa8.
## 4 chains, each with iter=4000; warmup=2000; thin=1; 
## post-warmup draws per chain=2000, total post-warmup draws=8000.
## 
##               mean se_mean   sd  2.5%  25%  50%  75% 97.5% n_eff Rhat
## alpha         3.32    0.00 0.41  2.50 3.04 3.32 3.59  4.12 16572    1
## beta_x        0.67    0.01 0.64 -0.62 0.25 0.68 1.10  1.91 13464    1
## sigma_state   1.19    0.01 0.27  0.67 1.02 1.19 1.36  1.70  1830    1
## sigma_ability 2.86    0.01 0.60  1.68 2.47 2.86 3.26  4.10  6531    1
## sigma         6.80    0.01 0.39  6.08 6.53 6.79 7.06  7.61  4144    1
## 
## Samples were drawn using NUTS(diag_e) at Mon Aug 23 18:34:45 2021.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).</code></pre>
<p>And we won’t look at every team but we can plot the model’s estimates of team 1’s ability against team 1’s actual ability. The model looks about right in the early part of the season but begins overrating team 1 later in the season.</p>
<pre class="r"><code>mu &lt;- rstan::extract(fit, pars = &#39;mu&#39;)$mu[,,1]

med &lt;- apply(mu, 2, median)
q_025 &lt;- apply(mu, 2, quantile, .025)
q_25 &lt;- apply(mu, 2, quantile, .25)
q_75 &lt;- apply(mu, 2, quantile, .75)
q_975 &lt;- apply(mu, 2, quantile, .975)
ability_t1 &lt;- filter(abilities, team_id == 1)

team_1 &lt;- data.frame(med, q_025, q_25, q_75, q_975, week, ability = ability_t1$ability)

ggplot(team_1, aes(y = ability, x = week)) + 
  geom_point(colour = &#39;red&#39;, size = 2) +
  geom_linerange(aes(ymin = q_025, ymax = q_975)) + 
  geom_point(data = team_1, aes(x = week, y = med), size = 2) +
  xlab(&#39;Week&#39;) +
  ylab(&#39;Ability&#39;)</code></pre>
<p><img src="/post/2021-08-22-state-space-season-simulation_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>Why would team 1 be overrated at the end of the year? Their end of year results were really good!</p>
<pre class="r"><code>filter(games, team_1 == 1 | team_2 == 1) %&gt;%
  mutate(team_1_margin = if_else(team_1 == 1, score_diff, score_diff * -1)) %&gt;%
  ggplot(aes(x = week, y = team_1_margin)) +
  geom_point() +
  geom_line() +
  xlab(&#39;Week&#39;) +
  ylab(&#39;Team 1 Margin of Victory&#39;)</code></pre>
<p><img src="/post/2021-08-22-state-space-season-simulation_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
</div>
<div id="concluding-thoughts" class="section level2">
<h2>Concluding Thoughts</h2>
<p>This is an extremely basic model to track changes in ability but that has a ton of useful applications. You can pretty easily extend this to include multiple indicators or build in different distributions on the state shocks.</p>
</div>

</main>

  <footer>
  <script src="//yihui.name/js/math-code.js"></script>
<script async src="//mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>

<script async src="//yihui.name/js/center-img.js"></script>

  
  <hr/>
  <a href="https://github.com/richjand">Github</a> | <a href="https://www.linkedin.com/in/richard-anderson-a9b445b2/">LinkedIn</a> | <a href="https://www.twitter.com/richjand">Twitter</a>
  
  </footer>
  </body>
</html>

